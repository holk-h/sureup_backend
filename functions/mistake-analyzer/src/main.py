"""
L1-Trigger: mistake-analyzer (Task Queue ç‰ˆæœ¬)
é”™é¢˜åˆ†æå™¨ - å°†ä»»åŠ¡å…¥é˜Ÿåˆ° Worker ç³»ç»Ÿï¼Œä¸æ‰§è¡Œå®é™…åˆ†æ

Event Trigger: 
- databases.*.collections.mistake_records.documents.*.create
- databases.*.collections.mistake_records.documents.*.update

æ–°è®¾è®¡ï¼šä¸€æ¡é”™é¢˜è®°å½• = ä¸€é“é¢˜ = ä¸€å¼ æˆ–å¤šå¼ å›¾ç‰‡ï¼ˆæ”¯æŒè·¨é¡µé¢˜ç›®ï¼‰

æ–°çš„å·¥ä½œæµç¨‹:
1. Flutter ç«¯ä¸Šä¼ å›¾ç‰‡åˆ° bucketï¼Œä¸ºæ¯é“é¢˜åˆ›å»ºä¸€ä¸ª mistake_record (analysisStatus: "pending")
   - å•å›¾é¢˜ï¼šoriginalImageIds: ["image_id_1"]
   - å¤šå›¾é¢˜ï¼šoriginalImageIds: ["image_id_1", "image_id_2", "image_id_3"]
2. æœ¬ function è¢«è‡ªåŠ¨è§¦å‘ï¼ˆcreate äº‹ä»¶ï¼‰
3. éªŒè¯ä»»åŠ¡å¹¶å…¥é˜Ÿåˆ° Worker ç³»ç»Ÿ
4. ç«‹å³è¿”å›ï¼ˆä¸ç­‰å¾…å¤„ç†ï¼‰
5. Worker å¼‚æ­¥æ‰§è¡Œå®é™…çš„åˆ†æä»»åŠ¡ï¼ˆæ”¯æŒå¤šå›¾ï¼‰
6. Worker æ›´æ–° analysisStatus ä¸º "completed" æˆ– "failed"
7. Flutter ç«¯é€šè¿‡ Realtime API è®¢é˜…æ›´æ–°ï¼Œå®æ—¶æ˜¾ç¤ºåˆ†æç»“æœ

ä¼˜åŠ¿:
- æ”¯æŒ 1000+ å¹¶å‘ä»»åŠ¡
- ä¸å— Appwrite Function å• worker é™åˆ¶
- é•¿æ—¶é—´ LLM è°ƒç”¨ä¸ä¼šé˜»å¡
- æ›´å¥½çš„é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶
- æ”¯æŒå•å›¾å’Œå¤šå›¾é¢˜ç›®ï¼ˆè·¨é¡µé¢˜ç›®ï¼‰
"""
import os
import json
import requests


# Configuration
WORKER_API_URL = os.environ.get('WORKER_API_URL', 'http://localhost:8000')
WORKER_API_TIMEOUT = int(os.environ.get('WORKER_API_TIMEOUT', '10'))  # å¢åŠ åˆ° 10 ç§’


def enqueue_analysis_task(record_data: dict) -> dict:
    """
    å°†åˆ†æä»»åŠ¡å…¥é˜Ÿåˆ° Worker ç³»ç»Ÿ
    
    Args:
        record_data: é”™é¢˜è®°å½•æ–‡æ¡£æ•°æ®
        
    Returns:
        å…¥é˜Ÿç»“æœå­—å…¸ {'success': bool, 'task_id': str, 'error': str}
    """
    record_id = record_data.get('$id')
    
    try:
        # æ„å»ºä»»åŠ¡æ•°æ®
        task_payload = {
            'task_type': 'mistake_analyzer',
            'task_data': {
                'record_data': record_data
            },
            'priority': 5  # é»˜è®¤ä¼˜å…ˆçº§ï¼ˆ1-10ï¼Œæ•°å­—è¶Šå°ä¼˜å…ˆçº§è¶Šé«˜ï¼‰
        }
        
        # è°ƒç”¨ Worker API å…¥é˜Ÿ
        response = requests.post(
            f"{WORKER_API_URL}/tasks/enqueue",
            json=task_payload,
            timeout=WORKER_API_TIMEOUT
        )
        
        response.raise_for_status()
        result = response.json()
        
        print(f"âœ… ä»»åŠ¡å·²å…¥é˜Ÿ: record_id={record_id}, task_id={result.get('task_id')}")
        
        return {
            'success': True,
            'task_id': result.get('task_id'),
            'message': 'ä»»åŠ¡å·²å…¥é˜Ÿï¼Œç­‰å¾…å¤„ç†',
            'error': None
        }
        
    except requests.exceptions.Timeout:
        error_msg = f"Worker API è¶…æ—¶ï¼ˆ{WORKER_API_TIMEOUT}ç§’ï¼‰"
        print(f"âŒ å…¥é˜Ÿå¤±è´¥: {error_msg}")
        return {
            'success': False,
            'task_id': None,
            'message': None,
            'error': error_msg
        }
        
    except requests.exceptions.RequestException as e:
        error_msg = f"Worker API è¯·æ±‚å¤±è´¥: {str(e)}"
        print(f"âŒ å…¥é˜Ÿå¤±è´¥: {error_msg}")
        return {
            'success': False,
            'task_id': None,
            'message': None,
            'error': error_msg
        }
        
    except Exception as e:
        error_msg = f"æœªçŸ¥é”™è¯¯: {str(e)}"
        print(f"âŒ å…¥é˜Ÿå¤±è´¥: {error_msg}")
        return {
            'success': False,
            'task_id': None,
            'message': None,
            'error': error_msg
        }


def main(context):
    """Main entry point for Appwrite Event Trigger"""
    try:
        req = context.req
        
        # è§£æ event æ•°æ®
        event_body = req.body
        if isinstance(event_body, str):
            event_data = json.loads(event_body)
        else:
            event_data = event_body
        
        context.log(f"æ”¶åˆ°äº‹ä»¶: {json.dumps(event_data, ensure_ascii=False)[:500]}")
        
        record_data = event_data
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†æï¼ˆåªå¤„ç† pending çŠ¶æ€ï¼‰
        analysis_status = record_data.get('analysisStatus', 'pending')
        
        if analysis_status != 'pending':
            context.log(f"â­ï¸  è·³è¿‡åˆ†æ: çŠ¶æ€æ˜¯ {analysis_status}")
            return context.res.empty()
        
        # éªŒè¯å¿…è¦å­—æ®µ
        record_id = record_data.get('$id')
        original_image_ids = record_data.get('originalImageIds', [])
        
        if not record_id:
            context.error("é”™é¢˜è®°å½•ç¼ºå°‘ID")
            return context.res.empty()
            
        if not original_image_ids or len(original_image_ids) == 0:
            context.error(f"é”™é¢˜è®°å½• {record_id} ç¼ºå°‘å›¾ç‰‡ID")
            return context.res.empty()
        
        # è®°å½•å›¾ç‰‡æ•°é‡
        image_count = len(original_image_ids)
        is_multi_photo = image_count > 1
        context.log(f"ğŸ“¸ å‡†å¤‡åˆ†æ: record_id={record_id}, å›¾ç‰‡æ•°={image_count}, å¤šå›¾é¢˜={is_multi_photo}")
        
        # å°†ä»»åŠ¡å…¥é˜Ÿåˆ° Worker ç³»ç»Ÿ
        result = enqueue_analysis_task(record_data)
        
        if result['success']:
            context.log(f"âœ… ä»»åŠ¡å…¥é˜ŸæˆåŠŸ: record_id={record_id}, task_id={result.get('task_id')}, å›¾ç‰‡æ•°={image_count}")
        else:
            context.error(f"âŒ ä»»åŠ¡å…¥é˜Ÿå¤±è´¥: record_id={record_id}, å›¾ç‰‡æ•°={image_count}, error={result.get('error')}")
        
        # æ— è®ºæˆåŠŸæˆ–å¤±è´¥ï¼Œéƒ½ç«‹å³è¿”å›ï¼ˆä¸é˜»å¡ï¼‰
        # Worker ç³»ç»Ÿä¼šå¼‚æ­¥å¤„ç†ä»»åŠ¡å¹¶æ›´æ–°æ•°æ®åº“
        return context.res.empty()
        
    except Exception as e:
        context.error(f"âŒ Function å¤„ç†å¤±è´¥: {str(e)}")
        return context.res.empty()
