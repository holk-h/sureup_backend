"""
å›¾ç‰‡åˆ†ææ¨¡å—
è´Ÿè´£å¤„ç†é”™é¢˜å›¾ç‰‡çš„ AI è§†è§‰åˆ†æ

ä½¿ç”¨ LLM çš„è§†è§‰èƒ½åŠ›ç›´æ¥åˆ†æå›¾ç‰‡ï¼Œæå–é¢˜ç›®ä¿¡æ¯å¹¶è½¬æ¢ä¸º Markdown æ ¼å¼

å†…éƒ¨ç»Ÿä¸€ä½¿ç”¨ base64 æ ¼å¼å¤„ç†å›¾ç‰‡
å›¾ç‰‡å·²ç”± Flutter ç«¯ä¸Šä¼ åˆ° bucketï¼Œæ­¤æ¨¡å—åªè´Ÿè´£åˆ†æ
"""
import os
import json
import base64
from typing import Dict, List, Optional
from appwrite.client import Client
from appwrite.services.databases import Databases
from appwrite.query import Query

from workers.mistake_analyzer.llm_provider import get_llm_provider


# å¸¸é‡é…ç½®
DATABASE_ID = os.environ.get('APPWRITE_DATABASE_ID', 'main')
COLLECTION_MODULES = 'knowledge_points_library'

# å­¦ç§‘ä¸­æ–‡æ˜ å°„
SUBJECT_NAMES = {
    'math': 'æ•°å­¦',
    'physics': 'ç‰©ç†',
    'chemistry': 'åŒ–å­¦',
    'biology': 'ç”Ÿç‰©',
    'chinese': 'è¯­æ–‡',
    'english': 'è‹±è¯­',
    'history': 'å†å²',
    'geography': 'åœ°ç†',
    'politics': 'æ”¿æ²»'
}

# é¢˜ç›®ç±»å‹
QUESTION_TYPES = ['choice', 'fillBlank', 'shortAnswer', 'essay']


# ============= å·¥å…·å‡½æ•° =============

def create_appwrite_client() -> Client:
    """åˆ›å»º Appwrite Client"""
    client = Client()
    client.set_endpoint(os.environ.get('APPWRITE_ENDPOINT', 'https://cloud.appwrite.io/v1'))
    client.set_project(os.environ['APPWRITE_PROJECT_ID'])
    client.set_key(os.environ['APPWRITE_API_KEY'])
    return client


def clean_base64(image_base64: str) -> str:
    """
    æ¸…ç† base64 å­—ç¬¦ä¸²ï¼Œå»é™¤ data:image å‰ç¼€
    
    Args:
        image_base64: å¯èƒ½åŒ…å«å‰ç¼€çš„ base64 å­—ç¬¦ä¸²
        
    Returns:
        çº¯ base64 å­—ç¬¦ä¸²
    """
    if ',' in image_base64:
        return image_base64.split(',', 1)[1]
    return image_base64


def clean_json_response(response: str) -> str:
    """
    æ¸…ç† LLM å“åº”ä¸­çš„ä»£ç å—æ ‡è®°
    
    æ³¨æ„ï¼šä¸å¤„ç† LaTeX å…¬å¼ä¸­çš„åæ–œæ ï¼Œå› ä¸º json.loads ä¼šæ­£ç¡®å¤„ç†å®ƒä»¬
    """
    response = response.strip()
    if response.startswith('```json'):
        response = response[7:]
    elif response.startswith('```'):
        response = response[3:]
    if response.endswith('```'):
        response = response[:-3]
    return response.strip()


def parse_segmented_response(response: str) -> Dict:
    """
    è§£æåˆ†æ®µæ ‡è®°æ ¼å¼çš„ LLM å“åº”
    
    æ ¼å¼ç¤ºä¾‹ï¼š
    ##TYPE##
    choice
    
    ##SUBJECT##
    math
    
    ##CONTENT##
    é¢˜ç›®å†…å®¹...
    
    ##OPTIONS##
    A. é€‰é¡¹1
    B. é€‰é¡¹2
    
    ##END##
    
    Args:
        response: LLM è¿”å›çš„åˆ†æ®µæ ‡è®°æ ¼å¼æ–‡æœ¬
        
    Returns:
        {'content': str, 'type': str, 'options': list, 'subject': str}
        
    Raises:
        ValueError: è§£æå¤±è´¥
    """
    import re
    
    # æ¸…ç†å¯èƒ½çš„ä»£ç å—æ ‡è®°
    response = response.strip()
    if response.startswith('```'):
        # å»é™¤å¼€å¤´çš„ä»£ç å—æ ‡è®°
        lines = response.split('\n')
        if lines[0].startswith('```'):
            lines = lines[1:]
        if lines and lines[-1].strip() == '```':
            lines = lines[:-1]
        response = '\n'.join(lines)
    
    # ä½¿ç”¨æ­£åˆ™æå–å„ä¸ªéƒ¨åˆ†ï¼ˆå¿½ç•¥å‰åç©ºç™½ï¼‰
    sections = {}
    
    # æå– TYPE
    type_match = re.search(r'##TYPE##\s*\n\s*(\w+)', response, re.IGNORECASE)
    if type_match:
        sections['type'] = type_match.group(1).strip()
    
    # æå– SUBJECT
    subject_match = re.search(r'##SUBJECT##\s*\n\s*(\w+)', response, re.IGNORECASE)
    if subject_match:
        sections['subject'] = subject_match.group(1).strip()
    
    # æå– CONTENTï¼ˆåˆ°ä¸‹ä¸€ä¸ªæ ‡è®°ä¸ºæ­¢ï¼‰
    content_match = re.search(r'##CONTENT##\s*\n(.*?)(?=##OPTIONS##|##END##)', response, re.DOTALL | re.IGNORECASE)
    if content_match:
        sections['content'] = content_match.group(1).strip()
    
    # æå– OPTIONSï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    options_match = re.search(r'##OPTIONS##\s*\n(.*?)(?=##END##)', response, re.DOTALL | re.IGNORECASE)
    if options_match:
        options_text = options_match.group(1).strip()
        if options_text:
            # æŒ‰è¡Œåˆ†å‰²é€‰é¡¹ï¼Œè¿‡æ»¤ç©ºè¡Œ
            sections['options'] = [
                line.strip() 
                for line in options_text.split('\n') 
                if line.strip()
            ]
        else:
            sections['options'] = []
    else:
        sections['options'] = []
    
    # éªŒè¯å¿…éœ€å­—æ®µ
    if 'type' not in sections:
        raise ValueError("ç¼ºå°‘ ##TYPE## æ ‡è®°")
    if 'subject' not in sections:
        raise ValueError("ç¼ºå°‘ ##SUBJECT## æ ‡è®°")
    if 'content' not in sections:
        raise ValueError("ç¼ºå°‘ ##CONTENT## æ ‡è®°")
    
    return sections


def fix_json_escaping(json_str: str) -> str:
    """
    ä¿®å¤ JSON å­—ç¬¦ä¸²ä¸­çš„è½¬ä¹‰é—®é¢˜
    
    é—®é¢˜ï¼šLLM å¯èƒ½è¿”å›æ— æ•ˆçš„è½¬ä¹‰å­—ç¬¦ï¼Œç‰¹åˆ«æ˜¯ LaTeX å…¬å¼ä¸­çš„åæ–œæ 
    ä¾‹å¦‚ï¼š\( åº”è¯¥æ˜¯ \\(ï¼Œ\frac åº”è¯¥æ˜¯ \\frac
    
    ç­–ç•¥ï¼š
    1. ä¿ç•™åˆæ³•çš„ JSON è½¬ä¹‰åºåˆ—ï¼š\n \t \r \" \\ \/
    2. å°†å…¶ä»–å•åæ–œæ ï¼ˆç‰¹åˆ«æ˜¯ LaTeX å‘½ä»¤ï¼‰è½¬æ¢ä¸ºåŒåæ–œæ 
    
    Args:
        json_str: å¾…ä¿®å¤çš„ JSON å­—ç¬¦ä¸²
        
    Returns:
        ä¿®å¤åçš„ JSON å­—ç¬¦ä¸²
    """
    import re
    
    # å®šä¹‰åˆæ³•çš„ JSON è½¬ä¹‰åºåˆ—ï¼ˆåœ¨ JSON å­—ç¬¦ä¸²å€¼ä¸­ï¼‰
    # è¿™äº›ä¸éœ€è¦ä¿®æ”¹
    legal_escapes = ['\\n', '\\t', '\\r', '\\b', '\\f', '\\"', '\\\\', '\\/']
    
    # LaTeX ç›¸å…³çš„åæ–œæ æ¨¡å¼ï¼ˆè¿™äº›éœ€è¦å˜æˆåŒåæ–œæ ï¼‰
    # åŒ¹é… \ åé¢è·Ÿç€å­—æ¯æˆ–æ‹¬å·ï¼ˆLaTeX å‘½ä»¤æˆ–å…¬å¼æ ‡è®°ï¼‰
    latex_pattern = r'(?<!\\)\\(?=[a-zA-Z\(\)\[\]])'
    
    # æ›¿æ¢ç­–ç•¥ï¼š
    # 1. æ‰¾åˆ°æ‰€æœ‰åœ¨å¼•å·å†…çš„å­—ç¬¦ä¸²å€¼
    # 2. åœ¨è¿™äº›å­—ç¬¦ä¸²ä¸­ï¼Œå°† LaTeX ç›¸å…³çš„å•åæ–œæ æ›¿æ¢ä¸ºåŒåæ–œæ 
    
    result = []
    i = 0
    in_string = False
    escape_next = False
    
    while i < len(json_str):
        char = json_str[i]
        
        # å¤„ç†å­—ç¬¦ä¸²å†…å®¹
        if char == '"' and not escape_next:
            in_string = not in_string
            result.append(char)
            i += 1
            continue
        
        # åœ¨å­—ç¬¦ä¸²å†…éƒ¨å¤„ç†è½¬ä¹‰
        if in_string:
            if escape_next:
                # ä¸Šä¸€ä¸ªå­—ç¬¦æ˜¯åæ–œæ 
                if char in 'ntrfb"\\/':
                    # åˆæ³•çš„ JSON è½¬ä¹‰åºåˆ—ï¼Œä¿æŒä¸å˜
                    result.append(char)
                else:
                    # ä¸æ˜¯åˆæ³•çš„è½¬ä¹‰åºåˆ—ï¼Œåœ¨åæ–œæ å‰å†åŠ ä¸€ä¸ªåæ–œæ 
                    # ä¾‹å¦‚ \( å˜æˆ \\(ï¼Œ\frac å˜æˆ \\frac
                    result.append('\\')
                    result.append(char)
                escape_next = False
            elif char == '\\':
                # é‡åˆ°åæ–œæ ï¼Œæ ‡è®°ä¸‹ä¸€ä¸ªå­—ç¬¦éœ€è¦æ£€æŸ¥
                result.append(char)
                escape_next = True
            else:
                result.append(char)
        else:
            # ä¸åœ¨å­—ç¬¦ä¸²å†…ï¼Œç›´æ¥æ·»åŠ 
            result.append(char)
            escape_next = False
        
        i += 1
    
    return ''.join(result)


def safe_json_loads(json_str: str, debug_name: str = "JSON") -> dict:
    """
    å®‰å…¨åœ°è§£æ JSONï¼Œå¸¦æœ‰å¤šé‡å®¹é”™æœºåˆ¶
    
    Args:
        json_str: JSON å­—ç¬¦ä¸²
        debug_name: è°ƒè¯•ç”¨åç§°
        
    Returns:
        è§£æåçš„å­—å…¸
        
    Raises:
        ValueError: æ‰€æœ‰è§£æå°è¯•éƒ½å¤±è´¥
    """
    import re
    
    # å°è¯•1ï¼šç›´æ¥è§£æ
    try:
        return json.loads(json_str)
    except json.JSONDecodeError as e1:
        print(f"âš ï¸ {debug_name} è§£æå¤±è´¥ï¼ˆç¬¬1æ¬¡ï¼‰: {str(e1)}")
        print(f"   é”™è¯¯ä½ç½®é™„è¿‘çš„å†…å®¹: ...{json_str[max(0, e1.pos-30):e1.pos+30]}...")
    
    # å°è¯•2ï¼šä½¿ç”¨ strict=Falseï¼ˆå…è®¸æ§åˆ¶å­—ç¬¦ï¼‰
    try:
        return json.loads(json_str, strict=False)
    except json.JSONDecodeError as e2:
        print(f"âš ï¸ {debug_name} è§£æå¤±è´¥ï¼ˆç¬¬2æ¬¡ï¼Œstrict=Falseï¼‰: {str(e2)}")
    
    # å°è¯•3ï¼šä¿®å¤è½¬ä¹‰é—®é¢˜
    try:
        fixed_json = fix_json_escaping(json_str)
        print(f"ğŸ”§ å°è¯•ä¿®å¤è½¬ä¹‰å­—ç¬¦...")
        return json.loads(fixed_json)
    except json.JSONDecodeError as e3:
        print(f"âš ï¸ {debug_name} è§£æå¤±è´¥ï¼ˆç¬¬3æ¬¡ï¼Œä¿®å¤è½¬ä¹‰åï¼‰: {str(e3)}")
        print(f"   ä¿®å¤åçš„JSONå‰200å­—ç¬¦: {fixed_json[:200]}")
    
    # å°è¯•4ï¼šæ¿€è¿›çš„ä¿®å¤ - å°†æ‰€æœ‰å•åæ–œæ éƒ½åŠ å€ï¼ˆé™¤äº†å·²ç»æ˜¯åŒåæ–œæ çš„ï¼‰
    try:
        aggressive_fix = re.sub(r'(?<!\\)\\(?!\\)', r'\\\\', json_str)
        print(f"ğŸ”§ å°è¯•æ¿€è¿›ä¿®å¤ï¼ˆæ‰€æœ‰å•åæ–œæ åŠ å€ï¼‰...")
        return json.loads(aggressive_fix)
    except json.JSONDecodeError as e4:
        print(f"âš ï¸ {debug_name} è§£æå¤±è´¥ï¼ˆç¬¬4æ¬¡ï¼Œæ¿€è¿›ä¿®å¤ï¼‰: {str(e4)}")
    
    # æ‰€æœ‰å°è¯•éƒ½å¤±è´¥ï¼Œè®°å½•å®Œæ•´å†…å®¹å¹¶æŠ›å‡ºå¼‚å¸¸
    print(f"âŒ {debug_name} è§£æå½»åº•å¤±è´¥ï¼")
    print(f"ğŸ“„ å®Œæ•´ JSON å†…å®¹ï¼š\n{json_str}\n")
    raise ValueError(f"{debug_name} è§£æå¤±è´¥ï¼šå°è¯•äº†4ç§æ–¹æ³•éƒ½æ— æ³•è§£æã€‚æœ€åä¸€æ¬¡é”™è¯¯ï¼š{str(e4)}")


def fix_latex_escaping(text: str) -> str:
    """
    ä¿®æ­£ LaTeX å…¬å¼ä¸­çš„è½¬ä¹‰é—®é¢˜ï¼ˆç”¨äº JSON è§£æåçš„æ–‡æœ¬ï¼‰
    
    æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°å¤„ç†çš„æ˜¯ JSON è§£æ**å**çš„ Python å­—ç¬¦ä¸²
    
    å‰ç«¯ gpt_markdown è¦æ±‚çš„æ ¼å¼ï¼š
    - è¡Œå†…å…¬å¼ï¼š\( ... \)  (å•åæ–œæ )
    - ç‹¬ç«‹å…¬å¼ï¼š\[ ... \]  (å•åæ–œæ )
    - LaTeX å‘½ä»¤ï¼š\fracã€\sqrt ç­‰ (å•åæ–œæ )
    
    å¦‚æœ LLM åœ¨ JSON ä¸­è¾“å‡ºäº† \\\\( ï¼ˆå››ä¸ªåæ–œæ ï¼‰ï¼Œè§£æåä¼šå˜æˆ \\(ï¼ˆåŒåæ–œæ ï¼‰
    æˆ‘ä»¬éœ€è¦å°†å…¶ä¿®æ­£ä¸º \(ï¼ˆå•åæ–œæ ï¼‰
    
    ç­–ç•¥ï¼šåœ¨ LaTeX å…¬å¼ä¸Šä¸‹æ–‡ä¸­ï¼Œå°†åŒåæ–œæ çš„ LaTeX å‘½ä»¤æ›¿æ¢ä¸ºå•åæ–œæ 
    
    Args:
        text: JSON è§£æåçš„æ–‡æœ¬ï¼ˆå¯èƒ½åŒ…å«åŒåæ–œæ çš„ LaTeX å‘½ä»¤ï¼‰
        
    Returns:
        ä¿®æ­£åçš„æ–‡æœ¬ï¼ˆå•åæ–œæ çš„ LaTeX å‘½ä»¤ï¼‰
    """
    import re
    
    # LaTeX å¸¸ç”¨å‘½ä»¤åˆ—è¡¨ï¼ˆç”¨äºåŒ¹é…ï¼‰
    latex_commands = [
        'frac', 'sqrt', 'int', 'sum', 'prod', 'lim',
        'sin', 'cos', 'tan', 'cot', 'sec', 'csc',
        'log', 'ln', 'exp',
        'alpha', 'beta', 'gamma', 'delta', 'epsilon', 'zeta', 'eta', 'theta', 'pi', 'sigma', 'omega', 'mu', 'nu', 'xi', 'rho', 'tau', 'phi', 'chi', 'psi',
        'Alpha', 'Beta', 'Gamma', 'Delta', 'Theta', 'Pi', 'Sigma', 'Omega',
        'times', 'div', 'pm', 'mp', 'cdot', 'ast',
        'leq', 'geq', 'neq', 'approx', 'equiv', 'sim',
        'infty', 'partial', 'nabla', 'forall', 'exists',
        'left', 'right', 'begin', 'end',
        'text', 'mathbf', 'mathrm', 'mathit', 'mathbb', 'mathcal',
    ]
    
    # ç­–ç•¥ï¼šæ‰¾åˆ°æ‰€æœ‰å…¬å¼åŒºåŸŸï¼Œåœ¨å…¬å¼å†…éƒ¨å°†åŒåæ–œæ æ›¿æ¢ä¸ºå•åæ–œæ 
    def fix_formula(match):
        """ä¿®æ­£å•ä¸ªå…¬å¼å†…çš„è½¬ä¹‰"""
        prefix = match.group(1)  # \( æˆ– \[
        content = match.group(2)  # å…¬å¼å†…å®¹
        suffix = match.group(3)  # \) æˆ– \]
        
        # åœ¨å…¬å¼å†…å®¹ä¸­ï¼Œå°†æ‰€æœ‰ LaTeX å‘½ä»¤çš„åŒåæ–œæ æ”¹ä¸ºå•åæ–œæ 
        for cmd in latex_commands:
            content = content.replace(f'\\\\{cmd}', f'\\{cmd}')
        
        return prefix + content + suffix
    
    # åŒ¹é…æ‰€æœ‰å…¬å¼ï¼š\( ... \) æˆ– \[ ... \]
    # ä½¿ç”¨éè´ªå©ªåŒ¹é…ï¼Œæ”¯æŒåµŒå¥—çš„æ‹¬å·
    text = re.sub(
        r'(\\[\(\[])(.*?)(\\[\)\]])',
        fix_formula,
        text,
        flags=re.DOTALL
    )
    
    return text


def create_fallback_result(subject: str, error_msg: str = '') -> Dict:
    """åˆ›å»ºå¤±è´¥æ—¶çš„å ä½ç»“æœ"""
    return {
        'content': f'åˆ†æå¤±è´¥: {error_msg}' if error_msg else 'é¢˜ç›®è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•',
        'type': 'shortAnswer',
        'subject': subject,
        'modules': ['æœªåˆ†ç±»'],
        'moduleIds': [],
        'knowledgePoints': [{'name': 'æœªåˆ†ç±»', 'module': 'æœªåˆ†ç±»', 'moduleId': None}],
        'options': [],
        'answer': '',
        'explanation': '',
        'difficulty': 3,
        'userAnswer': '',
        'confidence': 0.0,
        'error': error_msg
    }


# ============= ä¸»è¦åŠŸèƒ½å‡½æ•° =============

async def analyze_mistake_image(
    image_base64: str,
    user_id: str,
    databases: Optional[Databases] = None
) -> Dict:
    """
    åˆ†æé”™é¢˜å›¾ç‰‡å¹¶æå–é¢˜ç›®ä¿¡æ¯ï¼ˆå¼‚æ­¥ï¼‰
    
    ç»Ÿä¸€ä½¿ç”¨ base64 æ ¼å¼ï¼Œå›¾ç‰‡å·²ç»åœ¨ bucket ä¸­ï¼Œä¸éœ€è¦ä¿å­˜
    AI ä¼šè‡ªåŠ¨è¯†åˆ«å­¦ç§‘ã€æ¨¡å—å’ŒçŸ¥è¯†ç‚¹
    
    Args:
        image_base64: å›¾ç‰‡ base64 ç¼–ç ï¼ˆçº¯ base64 æˆ–åŒ…å« data:image å‰ç¼€ï¼‰
        user_id: ç”¨æˆ·IDï¼ˆç”¨äºè·å–å­¦æ®µä¿¡æ¯ï¼‰
        databases: Databases å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        åŒ…å«å­¦ç§‘ã€é¢˜ç›®å†…å®¹ã€ç±»å‹ã€æ¨¡å—ã€çŸ¥è¯†ç‚¹ç­‰çš„å­—å…¸
    """
    if not image_base64:
        raise ValueError("å¿…é¡»æä¾› image_base64")
    
    # æ¸…ç† base64 å­—ç¬¦ä¸²ï¼Œå»é™¤å¯èƒ½çš„å‰ç¼€
    clean_image_base64 = clean_base64(image_base64)
    
    if not clean_image_base64:
        raise ValueError("å›¾ç‰‡æ•°æ®æ— æ•ˆ")
    
    # åˆ†æå›¾ç‰‡ï¼šè¯†åˆ«å­¦ç§‘ + OCR + çŸ¥è¯†ç‚¹
    analysis_result = await analyze_with_llm_vision(clean_image_base64, user_id, databases)
    
    return analysis_result


async def analyze_with_llm_vision(
    image_base64: str,
    user_id: str,
    databases: Optional[Databases] = None
) -> Dict:
    """
    ä½¿ç”¨ LLM ä¸¤æ­¥åˆ†ææ³•ï¼ˆå†…éƒ¨å‡½æ•°ï¼Œåªæ¥å— base64ï¼Œå¼‚æ­¥ï¼‰
    
    1. OCRï¼šæå–é¢˜ç›®å†…å®¹å’Œæ ¼å¼
    2. åˆ†æï¼šè¯†åˆ«å­¦ç§‘ã€æ¨¡å—å’ŒçŸ¥è¯†ç‚¹
    
    Args:
        image_base64: çº¯ base64 å­—ç¬¦ä¸²ï¼ˆä¸å«å‰ç¼€ï¼‰
        user_id: ç”¨æˆ·IDï¼ˆç”¨äºè·å–å­¦æ®µä¿¡æ¯ï¼‰
        databases: Databases å®ä¾‹ï¼ˆå¯é€‰ï¼‰
    """
    try:
        # ç¬¬ä¸€æ­¥ï¼šOCR æå–é¢˜ç›®å†…å®¹å’Œå­¦ç§‘è¯†åˆ«
        step1 = await extract_question_content(image_base64)
        
        # ç¬¬äºŒæ­¥ï¼šåŸºäºé¢˜ç›®å†…å®¹å’Œå­¦ç§‘è¯†åˆ«æ¨¡å—å’ŒçŸ¥è¯†ç‚¹
        step2 = await analyze_subject_and_knowledge_points(
            content=step1['content'],
            question_type=step1['type'],
            subject=step1['subject'],
            user_id=user_id,
            databases=databases
        )
        
        # åˆå¹¶ç»“æœå¹¶è®¾ç½®é»˜è®¤å€¼
        return {
            **step1,
            **step2,
            'answer': '',
            'explanation': '',
            'difficulty': 3,
            'userAnswer': '',
            'confidence': 0.85
        }
        
    except Exception as e:
        print(f"LLM åˆ†æå¤±è´¥: {str(e)}")
        return create_fallback_result('unknown', str(e))


async def extract_question_content(
    image_base64: str
) -> Dict:
    """
    ç¬¬ä¸€æ­¥ï¼šOCR æå–é¢˜ç›®å†…å®¹å’Œå­¦ç§‘è¯†åˆ«ï¼ˆå†…éƒ¨å‡½æ•°ï¼Œå¼‚æ­¥ï¼‰
    
    ä½¿ç”¨åˆ†æ®µæ ‡è®°æ ¼å¼ï¼Œé¿å… LaTeX è½¬ä¹‰åœ°ç‹±
    
    Args:
        image_base64: çº¯ base64 å­—ç¬¦ä¸²ï¼ˆä¸å«å‰ç¼€ï¼‰
        
    Returns:
        {'content': str, 'type': str, 'options': list, 'subject': str}
    """
    system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„é¢˜ç›® OCR è¯†åˆ«ä¸“å®¶ï¼Œæ“…é•¿ä»å›¾ç‰‡ä¸­å‡†ç¡®æå–é¢˜ç›®æ–‡å­—å¹¶è¯†åˆ«å­¦ç§‘ã€‚

**æ ¸å¿ƒè¦æ±‚ï¼š**
1. æ‰€æœ‰æ•°å­¦ã€ç‰©ç†ã€åŒ–å­¦å…¬å¼å¿…é¡»ä½¿ç”¨ LaTeX æ ¼å¼
2. è¡Œå†…å…¬å¼ç”¨ \( ... \) åŒ…è£¹
3. ç‹¬ç«‹å…¬å¼ç”¨ \[ ... \] åŒ…è£¹ï¼Œå¹¶ç‹¬ç«‹æˆè¡Œ
4. è¯†åˆ«å®Œæ•´çš„å…¬å¼ç»“æ„ï¼ŒåŒ…æ‹¬åˆ†æ•°ã€æ ¹å·ã€ç§¯åˆ†ã€æ±‚å’Œç­‰
5. ä½¿ç”¨åˆ†æ®µæ ‡è®°æ ¼å¼è¿”å›ï¼ŒLaTeX å…¬å¼ç›´æ¥ä¹¦å†™ï¼Œä¸éœ€è¦ä»»ä½•è½¬ä¹‰"""
    
    user_prompt = r"""è¯·è¯†åˆ«è¿™å¼ é¢˜ç›®å›¾ç‰‡ï¼Œæå–ä»¥ä¸‹ä¿¡æ¯ï¼š

**è¦æå–çš„å†…å®¹ï¼š**
1. **é¢˜ç›®å†…å®¹**ï¼šè½¬æ¢ä¸º Markdown + LaTeX æ ¼å¼
   - æ‰€æœ‰å…¬å¼ç”¨ LaTeXï¼šå˜é‡ã€è¡¨è¾¾å¼ã€æ–¹ç¨‹å¼ç­‰
   - è¡Œå†…å…¬å¼ï¼š\( ... \)
   - ç‹¬ç«‹å…¬å¼ï¼š\[ ... \]ï¼ˆç‹¬ç«‹æˆè¡Œï¼‰
   - ä¿ç•™åŸå§‹ç»“æ„å’Œæ®µè½
   
2. **é¢˜ç›®ç±»å‹**ï¼šchoice/fillBlank/shortAnswer/essay

3. **é€‰é¡¹**ï¼ˆä»…é€‰æ‹©é¢˜ï¼‰ï¼šæ¯è¡Œä¸€ä¸ªé€‰é¡¹ï¼Œå…¬å¼ä¹Ÿç”¨ LaTeX

4. **å­¦ç§‘**ï¼šmath/physics/chemistry/biology/chinese/english/history/geography/politics

**è¿”å›æ ¼å¼ï¼ˆåˆ†æ®µæ ‡è®°ï¼Œä¸è¦ç”¨ä»£ç å—åŒ…è£¹ï¼‰ï¼š**

##TYPE##
é¢˜ç›®ç±»å‹

##SUBJECT##
å­¦ç§‘ä»£ç 

##CONTENT##
é¢˜ç›®å†…å®¹ï¼ˆMarkdown + LaTeXï¼ŒLaTeX å…¬å¼ç›´æ¥ä¹¦å†™ï¼Œä¸éœ€è¦è½¬ä¹‰ï¼‰

##OPTIONS##
é€‰é¡¹1
é€‰é¡¹2
...

##END##

**ç¤ºä¾‹1 - é€‰æ‹©é¢˜ï¼ˆæ•°å­¦ï¼‰ï¼š**

##TYPE##
choice

##SUBJECT##
math

##CONTENT##
å·²çŸ¥ \( m \)ã€\( n \) æ˜¯æ–¹ç¨‹ \( x^2 + 2020x + 7 = 0 \) çš„ä¸¤ä¸ªæ ¹ï¼Œåˆ™ \( (m^2 + 2019m + 6)(n^2 + 2021n + 8) \) çš„å€¼ä¸ºï¼ˆï¼‰

##OPTIONS##
A. 1
B. 2
C. 3
D. 4

##END##

**ç¤ºä¾‹2 - å¡«ç©ºé¢˜ï¼ˆç‰©ç†ï¼‰ï¼š**

##TYPE##
fillBlank

##SUBJECT##
physics

##CONTENT##
è´¨é‡ä¸º \( m \) çš„ç‰©ä½“å—åŠ› \( F \)ï¼Œæ ¹æ®ç‰›é¡¿ç¬¬äºŒå®šå¾‹ \( F = ma \)ï¼Œåˆ™åŠ é€Ÿåº¦ \( a \) = ______ã€‚

##OPTIONS##

##END##

**ç¤ºä¾‹3 - è§£ç­”é¢˜ï¼ˆæ•°å­¦ï¼‰ï¼š**

##TYPE##
shortAnswer

##SUBJECT##
math

##CONTENT##
è®¡ç®—å®šç§¯åˆ†ï¼š

\[
\int_0^1 x^2 \, dx
\]

è¯·å†™å‡ºè¯¦ç»†æ­¥éª¤ã€‚

##OPTIONS##

##END##

**ç¤ºä¾‹4 - çŸ©é˜µï¼ˆæ•°å­¦ï¼‰ï¼š**

##TYPE##
shortAnswer

##SUBJECT##
math

##CONTENT##
æ±‚çŸ©é˜µçš„è¡Œåˆ—å¼ï¼š

\[
\begin{bmatrix}
1 & 2 & 3 \\
4 & 5 & 6 \\
7 & 8 & 9
\end{bmatrix}
\]

##OPTIONS##

##END##

**LaTeX å¸¸ç”¨è¯­æ³•ï¼š**
- åˆ†æ•°ï¼š\frac{a}{b}
- ä¸Šæ ‡ï¼šx^2, x^{n+1}
- ä¸‹æ ‡ï¼šx_i, a_{ij}
- æ ¹å·ï¼š\sqrt{x}, \sqrt[3]{x}
- ç§¯åˆ†ï¼š\int_a^b
- æ±‚å’Œï¼š\sum_{i=1}^n
- å¸Œè…Šå­—æ¯ï¼š\alpha, \beta, \theta, \pi
- è¿ç®—ç¬¦ï¼š\times, \div, \pm, \leq, \geq
- çŸ©é˜µï¼š\begin{bmatrix} ... \end{bmatrix}

**é‡è¦ï¼š**
- æ ‡è®°ç¬¦å·å¿…é¡»ç‹¬å ä¸€è¡Œ
- è¡Œå†…å…¬å¼ç”¨ \( ... \)ï¼Œå—çº§å…¬å¼ç”¨ \[ ... \]
- LaTeX å…¬å¼ç›´æ¥ä¹¦å†™ï¼Œä¸éœ€è¦è½¬ä¹‰åæ–œæ 
- OPTIONS éƒ¨åˆ†å¦‚æœæ˜¯éé€‰æ‹©é¢˜ï¼Œç•™ç©ºå³å¯"""

    response = None
    try:
        llm = get_llm_provider()
        response = await llm.chat_with_vision(
            prompt=user_prompt,
            image_base64=image_base64,
            system_prompt=system_prompt,
            temperature=0.3,
            max_tokens=3000,
            thinking_enabled=True,      # å¯ç”¨æ€è€ƒæ¨¡å¼
            reasoning_effort="low"      # è®¾ç½®æ¨ç†æ·±åº¦ä¸º low
        )
        
        print(f"ğŸ“‹ LLM è¿”å›çš„åˆ†æ®µæ ¼å¼ï¼ˆå‰300å­—ç¬¦ï¼‰: {response[:300]}...")
        
        # è§£æåˆ†æ®µæ ‡è®°æ ¼å¼
        result = parse_segmented_response(response)
        
        print(f"âœ… åˆ†æ®µæ ¼å¼è§£ææˆåŠŸï¼é¢˜ç›®ç±»å‹: {result.get('type', 'æœªçŸ¥')}, å­¦ç§‘: {result.get('subject', 'æœªçŸ¥')}")
        
        # éªŒè¯å’Œè§„èŒƒåŒ–
        if 'content' not in result or not result['content']:
            raise ValueError("ç¼ºå°‘é¢˜ç›®å†…å®¹")
        if 'type' not in result or result['type'] not in QUESTION_TYPES:
            result['type'] = 'shortAnswer'
        if not isinstance(result.get('options', []), list):
            result['options'] = []
        if 'subject' not in result or not result['subject']:
            result['subject'] = 'math'  # é»˜è®¤æ•°å­¦
        
        return result
        
    except Exception as e:
        print(f"é¢˜ç›®æå–å¤±è´¥: {str(e)}")
        if response:
            print(f"åŸå§‹å“åº”: {response[:500]}...")
        raise


def get_existing_modules(
    subject: str,
    user_id: str,
    databases: Optional[Databases] = None
) -> List[Dict]:
    """
    è·å–ç”¨æˆ·å­¦æ®µå¯¹åº”çš„å­¦ç§‘æ¨¡å—åˆ—è¡¨
    
    Args:
        subject: å­¦ç§‘ï¼ˆè‹±æ–‡ä»£ç å¦‚ 'math'ï¼‰
        user_id: ç”¨æˆ·IDï¼ˆç”¨äºè·å–å­¦æ®µä¿¡æ¯ï¼‰
        databases: Databases å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        [{'$id': str, 'name': str, 'description': str}, ...]
    """
    if not databases:
        databases = Databases(create_appwrite_client())
    
    try:
        # è·å–ç”¨æˆ·æ¡£æ¡ˆï¼Œç¡®å®šå­¦æ®µ
        from workers.mistake_analyzer.utils import get_user_profile, get_education_level_from_grade, get_subject_chinese_name
        
        user_profile = get_user_profile(databases, user_id)
        user_grade = user_profile.get('grade') if user_profile else None
        education_level = get_education_level_from_grade(user_grade)
        
        print(f"ç”¨æˆ·å¹´çº§: {user_grade}, å­¦æ®µ: {education_level}")
        
        # å°†å­¦ç§‘è‹±æ–‡ä»£ç è½¬æ¢ä¸ºä¸­æ–‡ï¼ˆæ•°æ®åº“ä¸­å­˜å‚¨çš„æ˜¯ä¸­æ–‡ï¼‰
        subject_chinese = get_subject_chinese_name(subject)
        
        # æŸ¥è¯¢å¯¹åº”å­¦æ®µçš„æ¨¡å—
        queries = [
            Query.equal('subject', subject_chinese),
            Query.equal('educationLevel', education_level),
            Query.equal('isActive', True),
            Query.order_asc('order'),
            Query.limit(100)
        ]
        
        result = databases.list_documents(
            database_id=DATABASE_ID,
            collection_id=COLLECTION_MODULES,
            queries=queries
        )
        
        modules = [
            {
                '$id': doc.get('$id', ''),
                'name': doc.get('name', ''),
                'description': doc.get('description', '')
            }
            for doc in result.get('documents', [])
        ]
        
        print(f"æ‰¾åˆ° {len(modules)} ä¸ª{SUBJECT_NAMES.get(subject, subject)}æ¨¡å—ï¼ˆå­¦æ®µ: {education_level}ï¼Œå­¦ç§‘ä¸­æ–‡: {subject_chinese}ï¼‰")
        return modules
        
    except Exception as e:
        print(f"è·å–å­¦ç§‘æ¨¡å—å¤±è´¥: {str(e)}")
        return []


def get_existing_knowledge_points_by_module(
    module_id: str,
    user_id: str,
    databases: Optional[Databases] = None
) -> List[str]:
    """
    è·å–ç”¨æˆ·åœ¨æŒ‡å®šæ¨¡å—ä¸‹å·²æœ‰çš„çŸ¥è¯†ç‚¹åç§°åˆ—è¡¨
    
    Args:
        module_id: æ¨¡å—ID
        user_id: ç”¨æˆ·ID
        databases: Databases å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        çŸ¥è¯†ç‚¹åç§°åˆ—è¡¨
    """
    if not databases:
        databases = Databases(create_appwrite_client())
    
    try:
        result = databases.list_documents(
            database_id=DATABASE_ID,
            collection_id='user_knowledge_points',
            queries=[
                Query.equal('userId', user_id),
                Query.equal('moduleId', module_id),
                Query.limit(100)
            ]
        )
        
        return [doc.get('name', '') for doc in result.get('documents', []) if doc.get('name')]
        
    except Exception as e:
        print(f"è·å–ç”¨æˆ·çŸ¥è¯†ç‚¹å¤±è´¥: {str(e)}")
        return []


async def analyze_subject_and_knowledge_points(
    content: str,
    question_type: str,
    subject: str,
    user_id: str,
    databases: Optional[Databases] = None
) -> Dict:
    """
    ç¬¬äºŒæ­¥ï¼šåŸºäºé¢˜ç›®å†…å®¹å’Œå­¦ç§‘è¯†åˆ«æ¨¡å—å’ŒçŸ¥è¯†ç‚¹ï¼ˆå¼‚æ­¥ï¼‰
    
    æ ¹æ®ç”¨æˆ·å­¦æ®µæä¾›ç›¸åº”çš„æ¨¡å—åˆ—è¡¨å’ŒçŸ¥è¯†ç‚¹åˆ—è¡¨ç»™ LLM
    
    æ–°å¢åŠŸèƒ½ï¼ˆv3.0ï¼‰ï¼š
    - è®¡ç®—çŸ¥è¯†ç‚¹æƒé‡ï¼ˆä¸»è¦è€ƒç‚¹ vs æ¬¡è¦è€ƒç‚¹ï¼‰
    - åˆ¤æ–­çŸ¥è¯†ç‚¹é‡è¦åº¦ï¼ˆhigh/basic/normalï¼‰
    - ç”Ÿæˆè§£é¢˜æç¤º
    
    Args:
        content: é¢˜ç›®å†…å®¹ï¼ˆMarkdown æ ¼å¼ï¼‰
        question_type: é¢˜ç›®ç±»å‹
        subject: å­¦ç§‘ä»£ç ï¼ˆä»ç¬¬ä¸€æ­¥è¯†åˆ«å¾—åˆ°ï¼‰
        user_id: ç”¨æˆ·IDï¼ˆç”¨äºè·å–å­¦æ®µä¿¡æ¯ï¼‰
        databases: Databases å®ä¾‹ï¼ˆå¯é€‰ï¼‰
        
    Returns:
        {
            'subject': str,
            'modules': list[str],
            'moduleIds': list[str],
            'knowledgePoints': list[{
                'name': str, 
                'module': str, 
                'moduleId': str,
                'weight': float,       # æ–°å¢ï¼šçŸ¥è¯†ç‚¹æƒé‡ 0.2-1.0
                'importance': str      # æ–°å¢ï¼šé‡è¦åº¦ high/basic/normal
            }],
            'primaryKnowledgePointId': str,           # æ–°å¢ï¼šä¸»è¦è€ƒç‚¹ID
            'knowledgePointWeights': dict,            # æ–°å¢ï¼š{kpId: weight}
            'solvingHint': str                        # æ–°å¢ï¼šè§£é¢˜æç¤º
        }
    """
    # è·å–è¯¥å­¦ç§‘åœ¨ç”¨æˆ·å­¦æ®µçš„æ¨¡å—åˆ—è¡¨
    available_modules = get_existing_modules(subject, user_id, databases)
    
    # æ„å»ºæ¨¡å—åˆ—è¡¨æ–‡æœ¬ï¼ˆç”¨äº promptï¼‰
    modules_text = ""
    modules_dict = {}  # ç”¨äºåç»­æŸ¥æ‰¾æ¨¡å—ID
    if available_modules:
        modules_list = []
        for mod in available_modules:
            modules_dict[mod['name']] = mod['$id']  # ä¿å­˜æ¨¡å—IDæ˜ å°„
            # ä½¿ç”¨æ‹¬å·å½¢å¼å±•ç¤ºæè¿°ï¼Œè®© LLM ç†è§£æ¨¡å—å«ä¹‰ï¼Œä½†è¿”å›æ—¶åªå¡«å†™æ¨¡å—å
            if mod.get('description'):
                modules_list.append(f"  - {mod['name']} ({mod['description']})")
            else:
                modules_list.append(f"  - {mod['name']}")
        modules_text = "\n".join(modules_list)
    
    system_prompt = """ä½ æ˜¯å­¦ç§‘çŸ¥è¯†ç‚¹åˆ†æä¸“å®¶ã€‚æ ¹æ®é¢˜ç›®å†…å®¹è¯†åˆ«æ¨¡å—å’ŒçŸ¥è¯†ç‚¹ã€‚

è¦æ±‚ï¼š
- å¿…é¡»ä»æä¾›çš„æ¨¡å—åˆ—è¡¨ä¸­é€‰æ‹©ï¼Œä¸èƒ½åˆ›é€ æ–°æ¨¡å—
- çŸ¥è¯†ç‚¹ä½¿ç”¨ç®€æ´çš„æ ‡å‡†æœ¯è¯­
- åŒºåˆ†ä¸»è¦è€ƒç‚¹å’Œæ¬¡è¦è€ƒç‚¹
- åˆ¤æ–­çŸ¥è¯†ç‚¹çš„é‡è¦ç¨‹åº¦
- ç”Ÿæˆç®€æ´çš„è§£é¢˜æç¤º

åˆ†ææŒ‡å¯¼ï¼š
1. æ¨¡å—é€‰æ‹©ï¼šæ‰¾æœ€ç›¸å…³çš„æ¨¡å—ï¼Œä¼˜å…ˆé€‰æ‹©é¢˜ç›®ä¸»è¦è€ƒæŸ¥çš„å†…å®¹æ‰€åœ¨æ¨¡å—
2. çŸ¥è¯†ç‚¹æå–ï¼šè¯†åˆ«ä¸€ä¸ªæˆ–å¤šä¸ªæ ¸å¿ƒçŸ¥è¯†ç‚¹ï¼Œé¿å…è¿‡åº¦ç»†åˆ†æˆ–è¿‡åº¦æ¦‚æ‹¬
3. æƒé‡åˆ¤æ–­ï¼šä¸»è¦è€ƒç‚¹weight=1.0ï¼Œæ¬¡è¦è€ƒç‚¹weight=0.3-0.5ï¼Œç›¸å…³ä½†ä¸é‡è¦çš„weight=0.2
4. é‡è¦åº¦åˆ¤æ–­ï¼š
   - highï¼šé«˜é¢‘è€ƒç‚¹ï¼ˆè€ƒè¯•å¸¸è€ƒçš„æ ¸å¿ƒçŸ¥è¯†ï¼‰
   - basicï¼šåŸºç¡€çŸ¥è¯†ç‚¹ï¼ˆå‰ç½®å¿…ä¼šçš„å†…å®¹ï¼‰
   - normalï¼šæ™®é€šè€ƒç‚¹
5. è§£é¢˜æç¤ºï¼šæ€»ç»“å…³é”®è§£é¢˜æ€è·¯ï¼Œå¦‚"çœ‹åˆ°XXæ¡ä»¶ï¼Œä¼˜å…ˆæƒ³XXæ–¹æ³•"""
    
    available_modules_hint = ""
    if modules_text:
        available_modules_hint = f"""

**å¯ç”¨æ¨¡å—åˆ—è¡¨ï¼ˆå¿…é¡»ä»ä¸­é€‰æ‹©ï¼‰ï¼š**
{modules_text}"""
    else:
        available_modules_hint = "\n\n**æ³¨æ„**ï¼šç³»ç»Ÿæš‚æ— æ¨¡å—æ•°æ®ï¼Œè¯·ä½¿ç”¨\"æœªåˆ†ç±»\"ã€‚"
    
    # è·å–å­¦ç§‘ä¸­æ–‡åç§°
    from workers.mistake_analyzer.utils import get_subject_chinese_name
    subject_chinese = get_subject_chinese_name(subject)
    
    user_prompt = f"""åˆ†æè¿™é“{subject_chinese}é¢˜ç›®çš„æ¨¡å—ã€çŸ¥è¯†ç‚¹åˆ†ç±»å’Œè§£é¢˜æç¤ºï¼š

**é¢˜ç›®ï¼š**
{content}
{available_modules_hint}

è¿”å› JSONï¼ˆä¸è¦ä»£ç å—ï¼‰ï¼š
{{
    "modules": ["æ¨¡å—åç§°"],
    "knowledgePoints": [
        {{
            "name": "çŸ¥è¯†ç‚¹å", 
            "module": "æ¨¡å—åç§°",
            "category": "primary",
            "importance": "high"
        }}
    ],
    "solvingHint": "è§£é¢˜æç¤º"
}}

**å­—æ®µè¯´æ˜ï¼š**
- modules: æ¨¡å—åç§°åˆ—è¡¨
  - **é‡è¦**ï¼šåªå¡«å†™æ¨¡å—çš„åç§°ï¼Œä¸è¦åŒ…å«æ‹¬å·åŠæ‹¬å·å†…çš„æè¿°
  - **é‡è¦**ï¼šä¾‹å¦‚ä¸Šé¢åˆ—è¡¨ä¸­çš„"äºŒæ¬¡å‡½æ•° (äºŒæ¬¡å‡½æ•°çš„å›¾åƒä¸æ€§è´¨)"ï¼Œä½ åªéœ€è¦å¡«å†™"äºŒæ¬¡å‡½æ•°"
  - **é‡è¦**ï¼šå¿…é¡»ä»"å¯ç”¨æ¨¡å—åˆ—è¡¨"ä¸­é€‰æ‹©ï¼ˆæ‹¬å·å‰çš„æ¨¡å—åï¼‰
- category: çŸ¥è¯†ç‚¹åˆ†ç±»
  - primaryï¼šä¸»è¦è€ƒç‚¹ï¼ˆé¢˜ç›®æ ¸å¿ƒè€ƒæŸ¥çš„ï¼Œ1-2ä¸ªï¼‰
  - secondaryï¼šæ¬¡è¦è€ƒç‚¹ï¼ˆé¢˜ç›®æ¶‰åŠä½†ä¸æ˜¯é‡ç‚¹ï¼‰
  - relatedï¼šç›¸å…³è€ƒç‚¹ï¼ˆèƒŒæ™¯çŸ¥è¯†ï¼Œä¸é‡è¦ï¼‰
- importance: çŸ¥è¯†ç‚¹é‡è¦åº¦
  - highï¼šé«˜é¢‘è€ƒç‚¹ï¼ˆè€ƒè¯•å¸¸è€ƒï¼‰
  - basicï¼šåŸºç¡€çŸ¥è¯†ç‚¹ï¼ˆå‰ç½®å¿…ä¼šï¼‰
  - normalï¼šæ™®é€šè€ƒç‚¹
- solvingHint: è§£é¢˜æç¤ºï¼ˆä¸€å¥è¯ï¼Œè®©å­¦ç”Ÿçœ‹åˆ°å°±çŸ¥é“æ€ä¹ˆåšï¼‰
  - è¦æ±‚ï¼šç®€æ´ã€ç›´æ¥ã€å®ç”¨ï¼Œç‚¹å‡ºå…³é”®æ€è·¯æˆ–æ–¹æ³•
  - ä¸è¦è¯´"çœ‹åˆ°XXä¼˜å…ˆæƒ³XX"è¿™ç§å¥—è¯ï¼Œç›´æ¥è¯´æ€ä¹ˆåš
  - ä¾‹å¦‚ï¼š"åˆ¤åˆ«å¼å¤§äº0æ—¶æœ‰ä¸¤ä¸ªä¸åŒå®æ ¹"ã€"å¯¹ç§°è½´å…¬å¼æ˜¯x=-b/2a"ã€"å…ˆå—åŠ›åˆ†æå†åˆ—ç‰›é¡¿ç¬¬äºŒå®šå¾‹æ–¹ç¨‹"

**æ³¨æ„ï¼š**
- å¤§å¤šæ•°é¢˜ç›®åªæ¶‰åŠ1ä¸ªæ¨¡å—ï¼Œè·¨æ¨¡å—ç»¼åˆé¢˜è¾ƒå°‘ï¼ˆä¸æ˜¯æ²¡æœ‰ï¼Œéœ€è¦è‡ªè¡Œåˆ¤æ–­ï¼‰
- æ¯ä¸ªçŸ¥è¯†ç‚¹å¿…é¡»å½’å±ä¸€ä¸ªæ¨¡å—
- ä¸»è¦è€ƒç‚¹ï¼ˆcategory=primaryï¼‰é€šå¸¸åªæœ‰1-2ä¸ª
- **è¿”å›æ—¶**ï¼šmodules å’Œ knowledgePoints ä¸­çš„ module å­—æ®µåªå¡«å†™æ¨¡å—åç§°ï¼ˆæ‹¬å·å‰çš„éƒ¨åˆ†ï¼‰ï¼Œä¸è¦åŒ…å«æ‹¬å·å’Œæè¿°

**ç¤ºä¾‹1ï¼ˆå•æ¨¡å—ï¼Œå•ä¸»è¦è€ƒç‚¹ï¼‰ï¼š**
{{
    "modules": ["äºŒæ¬¡å‡½æ•°"],
    "knowledgePoints": [
        {{
            "name": "åˆ¤åˆ«å¼",
            "module": "äºŒæ¬¡å‡½æ•°",
            "category": "primary",
            "importance": "high"
        }},
        {{
            "name": "ä¸€å…ƒäºŒæ¬¡æ–¹ç¨‹",
            "module": "äºŒæ¬¡å‡½æ•°",
            "category": "secondary",
            "importance": "basic"
        }}
    ],
    "solvingHint": "åˆ¤åˆ«å¼Î”=bÂ²-4acï¼ŒÎ”>0æœ‰ä¸¤ä¸ªä¸åŒå®æ ¹ï¼ŒÎ”=0æœ‰ä¸¤ä¸ªç›¸ç­‰å®æ ¹ï¼ŒÎ”<0æ— å®æ ¹"
}}

**ç¤ºä¾‹2ï¼ˆè·¨æ¨¡å—ï¼Œå¤šä¸»è¦è€ƒç‚¹ï¼‰ï¼š**
{{
    "modules": ["åŠ›å­¦", "è¿åŠ¨å­¦"],
    "knowledgePoints": [
        {{
            "name": "ç‰›é¡¿ç¬¬äºŒå®šå¾‹",
            "module": "åŠ›å­¦",
            "category": "primary",
            "importance": "high"
        }},
        {{
            "name": "åŒ€å˜é€Ÿç›´çº¿è¿åŠ¨",
            "module": "è¿åŠ¨å­¦",
            "category": "primary",
            "importance": "high"
        }},
        {{
            "name": "å—åŠ›åˆ†æ",
            "module": "åŠ›å­¦",
            "category": "secondary",
            "importance": "basic"
        }}
    ],
    "solvingHint": "å…ˆç”»å‡ºå—åŠ›å›¾è¿›è¡Œå—åŠ›åˆ†æï¼Œç„¶åæ ¹æ®F=maåˆ—æ–¹ç¨‹ï¼Œç»“åˆè¿åŠ¨å­¦å…¬å¼æ±‚è§£"
}}"""

    response = None
    try:
        llm = get_llm_provider()
        response = await llm.chat(
            prompt=user_prompt,
            system_prompt=system_prompt,
            temperature=0.,
            max_tokens=4000,
            thinking_enabled=True,
            reasoning_effort="medium"
        )
        
        # æ¸…ç†å“åº”
        cleaned_response = clean_json_response(response)
        
        print(f"ğŸ“‹ LLM è¿”å›çš„å­¦ç§‘åˆ†æ JSON: {cleaned_response}...")
        
        # ä½¿ç”¨å®‰å…¨çš„ JSON è§£æï¼ˆå¸¦å¤šé‡å®¹é”™æœºåˆ¶ï¼‰
        result = safe_json_loads(cleaned_response, "å­¦ç§‘å’ŒçŸ¥è¯†ç‚¹åˆ†æ")
        
        print(f"âœ… çŸ¥è¯†ç‚¹åˆ†æ JSON è§£ææˆåŠŸï¼")
        
        # ===== ç¬¬ä¸€æ­¥ï¼šè®¾ç½®å­¦ç§‘ï¼ˆä»å‚æ•°è·å–ï¼‰ =====
        result['subject'] = subject
        
        # ===== ç¬¬äºŒæ­¥ï¼šéªŒè¯å’Œè§„èŒƒåŒ–æ¨¡å—åˆ—è¡¨ =====
        modules_list = result.get('modules', [])
        
        if not isinstance(modules_list, list):
            modules_list = []
        
        if not modules_list:
            modules_list = ['æœªåˆ†ç±»']
        
        # éªŒè¯æ¯ä¸ªæ¨¡å—æ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
        validated_modules = []
        validated_module_ids = {}  # {module_name: module_id}
        
        for module_name in modules_list:
            # å®¹é”™å¤„ç†ï¼šå¤„ç†å¯èƒ½åŒ…å«çš„é¢å¤–æ ¼å¼
            original_name = module_name
            
            # 1. å¦‚æœåŒ…å«æ‹¬å·ï¼ˆå¦‚"æ¨¡å—å (æè¿°)"ï¼‰ï¼Œåªå–æ‹¬å·å‰çš„éƒ¨åˆ†
            if '(' in module_name or 'ï¼ˆ' in module_name:
                module_name = module_name.split('(')[0].split('ï¼ˆ')[0].strip()
            
            # 2. å¦‚æœåŒ…å«å†’å·ï¼ˆå¦‚"æ¨¡å—åï¼šæè¿°"ï¼‰ï¼Œåªå–å†’å·å‰çš„éƒ¨åˆ†
            if 'ï¼š' in module_name or ':' in module_name:
                module_name = module_name.split('ï¼š')[0].split(':')[0].strip()
            
            if original_name != module_name:
                print(f"âš  è‡ªåŠ¨ä¿®æ­£æ¨¡å—å: '{original_name}' -> '{module_name}'")
            
            if module_name in modules_dict:
                validated_modules.append(module_name)
                validated_module_ids[module_name] = modules_dict[module_name]
                print(f"âœ“ æ¨¡å—åŒ¹é…: {module_name}")
            else:
                print(f"âš  æ¨¡å— '{module_name}' ä¸åœ¨åˆ—è¡¨ä¸­ï¼Œå¿½ç•¥")
        
        # å¦‚æœæ‰€æœ‰æ¨¡å—éƒ½æ— æ•ˆï¼Œä½¿ç”¨"æœªåˆ†ç±»"
        if not validated_modules:
            print(f"âš  æ— æœ‰æ•ˆæ¨¡å—ï¼Œä½¿ç”¨'æœªåˆ†ç±»'")
            validated_modules = ['æœªåˆ†ç±»']
            if 'æœªåˆ†ç±»' in modules_dict:
                validated_module_ids['æœªåˆ†ç±»'] = modules_dict['æœªåˆ†ç±»']
        
        # ===== ç¬¬ä¸‰æ­¥ï¼šéªŒè¯å’Œè§„èŒƒåŒ–çŸ¥è¯†ç‚¹ =====
        knowledge_points = result.get('knowledgePoints', [])
        
        if not isinstance(knowledge_points, list):
            knowledge_points = []
        
        if not knowledge_points:
            knowledge_points = [{'name': 'æœªåˆ†ç±»', 'module': validated_modules[0], 'category': 'primary', 'importance': 'normal'}]
        
        # å¤„ç†æ¯ä¸ªçŸ¥è¯†ç‚¹
        processed_kps = []
        primary_kps = []  # ä¸»è¦è€ƒç‚¹åˆ—è¡¨ï¼ˆcategory=primaryçš„ï¼‰
        
        for kp in knowledge_points:
            if not isinstance(kp, dict):
                print(f"âš  çŸ¥è¯†ç‚¹æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {kp}")
                continue
            
            kp_name = kp.get('name', '')
            kp_module = kp.get('module', validated_modules[0])
            kp_category = kp.get('category', 'secondary')  # é»˜è®¤æ¬¡è¦
            kp_importance = kp.get('importance', 'normal')  # é»˜è®¤æ™®é€š
            
            # å®¹é”™å¤„ç†ï¼šå¤„ç†å¯èƒ½åŒ…å«çš„é¢å¤–æ ¼å¼
            if isinstance(kp_module, str):
                original_module = kp_module
                
                # 1. å¦‚æœåŒ…å«æ‹¬å·ï¼ˆå¦‚"æ¨¡å—å (æè¿°)"ï¼‰ï¼Œåªå–æ‹¬å·å‰çš„éƒ¨åˆ†
                if '(' in kp_module or 'ï¼ˆ' in kp_module:
                    kp_module = kp_module.split('(')[0].split('ï¼ˆ')[0].strip()
                
                # 2. å¦‚æœåŒ…å«å†’å·ï¼ˆå¦‚"æ¨¡å—åï¼šæè¿°"ï¼‰ï¼Œåªå–å†’å·å‰çš„éƒ¨åˆ†
                if 'ï¼š' in kp_module or ':' in kp_module:
                    kp_module = kp_module.split('ï¼š')[0].split(':')[0].strip()
                
                if original_module != kp_module:
                    print(f"âš  è‡ªåŠ¨ä¿®æ­£çŸ¥è¯†ç‚¹æ¨¡å—å: '{original_module}' -> '{kp_module}'")
            
            # ç¡®ä¿ category æ˜¯æœ‰æ•ˆå€¼
            if kp_category not in ['primary', 'secondary', 'related']:
                kp_category = 'secondary'
            
            # ç¡®ä¿ importance æ˜¯æœ‰æ•ˆå€¼
            if kp_importance not in ['high', 'basic', 'normal']:
                kp_importance = 'normal'
            
            if not kp_name:
                continue
            
            # ç¡®ä¿çŸ¥è¯†ç‚¹çš„æ¨¡å—åœ¨éªŒè¯åˆ—è¡¨ä¸­
            if kp_module not in validated_modules:
                print(f"âš  çŸ¥è¯†ç‚¹ '{kp_name}' çš„æ¨¡å— '{kp_module}' æ— æ•ˆï¼Œæ”¹ç”¨ '{validated_modules[0]}'")
                kp_module = validated_modules[0]
            
            # è·å–è¯¥æ¨¡å—ä¸‹å·²æœ‰çš„çŸ¥è¯†ç‚¹è¿›è¡ŒåŒ¹é…
            module_id = validated_module_ids.get(kp_module)
            if module_id and databases:
                existing_kp_names = get_existing_knowledge_points_by_module(module_id, user_id, databases)
                
                if kp_name in existing_kp_names:
                    print(f"  âœ“ çŸ¥è¯†ç‚¹åŒ¹é…: {kp_name} ({kp_module}) [{kp_category}] importance={kp_importance}")
                else:
                    print(f"  + æ–°çŸ¥è¯†ç‚¹: {kp_name} ({kp_module}) [{kp_category}] importance={kp_importance}")
            
            # è®°å½•ä¸»è¦è€ƒç‚¹ï¼ˆcategory=primaryçš„ï¼‰
            if kp_category == 'primary':
                primary_kps.append({
                    'name': kp_name,
                    'module': kp_module,
                    'moduleId': module_id,
                    'category': kp_category,
                    'importance': kp_importance
                })
            
            processed_kps.append({
                'name': kp_name,
                'module': kp_module,
                'moduleId': module_id,
                'category': kp_category,
                'importance': kp_importance
            })
        
        # ===== ç¬¬å››æ­¥ï¼šæå–è§£é¢˜æç¤º =====
        solving_hint = result.get('solvingHint', '')
        if not solving_hint or not isinstance(solving_hint, str):
            solving_hint = ''
        solving_hint = solving_hint.strip()[:200]  # é™åˆ¶é•¿åº¦
        
        print(f"ğŸ“ è§£é¢˜æç¤º: {solving_hint[:50]}..." if solving_hint else "âš  æœªæä¾›è§£é¢˜æç¤º")
        print(f"ğŸ¯ ä¸»è¦è€ƒç‚¹æ•°é‡: {len(primary_kps)}")
        
        # è¿”å›å¤„ç†åçš„ç»“æœ
        return {
            'subject': subject,
            'modules': validated_modules,
            'moduleIds': list(validated_module_ids.values()),
            'knowledgePoints': processed_kps,
            'primaryKnowledgePoints': primary_kps,  # ä¸»è¦è€ƒç‚¹åˆ—è¡¨ï¼ˆweight=1.0çš„ï¼‰
            'solvingHint': solving_hint  # è§£é¢˜æç¤º
        }
        
    except json.JSONDecodeError as e:
        print(f"JSON è§£æå¤±è´¥: {str(e)}, å“åº”: {response if response else 'æ— å“åº”'}")
        raise ValueError(f"çŸ¥è¯†ç‚¹åˆ†æå¤±è´¥: {str(e)}")
    except Exception as e:
        print(f"çŸ¥è¯†ç‚¹åˆ†æå¤±è´¥: {str(e)}")
        raise



