"""
Worker ä¸»åº”ç”¨
FastAPI + å¼‚æ­¥ä»»åŠ¡é˜Ÿåˆ—ï¼Œæ”¯æŒé«˜å¹¶å‘ä»»åŠ¡å¤„ç†
"""
# é‡è¦ï¼šæœ€å…ˆåŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

import asyncio
from contextlib import asynccontextmanager
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse
from typing import Dict, Any
from loguru import logger

from config import config
from task_queue.memory_queue import MemoryQueue
from task_queue.base import TaskQueue
from tasks import TaskBase, TaskResponse, TaskStatus, QueueStats, task_registry
from workers.mistake_analyzer import MistakeAnalyzerWorker
from workers.daily_task_generator import DailyTaskGeneratorWorker
from workers.accumulated_mistakes_analyzer import AccumulatedMistakesAnalyzerWorker


# ========== å…¨å±€å˜é‡ ==========
task_queue: TaskQueue = None
worker_tasks: list = []


# ========== åˆå§‹åŒ–å’Œæ¸…ç† ==========

async def init_queue():
    """åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—"""
    global task_queue
    
    if config.QUEUE_TYPE == 'memory':
        logger.info("ä½¿ç”¨å†…å­˜é˜Ÿåˆ—")
        task_queue = MemoryQueue()
    elif config.QUEUE_TYPE == 'redis':
        logger.warning("Redis é˜Ÿåˆ—å°šæœªå®ç°ï¼Œä½¿ç”¨å†…å­˜é˜Ÿåˆ—")
        task_queue = MemoryQueue()
    else:
        logger.warning(f"æœªçŸ¥çš„é˜Ÿåˆ—ç±»å‹: {config.QUEUE_TYPE}ï¼Œä½¿ç”¨å†…å­˜é˜Ÿåˆ—")
        task_queue = MemoryQueue()


def register_workers():
    """æ³¨å†Œæ‰€æœ‰ worker"""
    task_registry.register('mistake_analyzer', MistakeAnalyzerWorker)
    task_registry.register('daily_task_generator', DailyTaskGeneratorWorker)
    task_registry.register('accumulated_mistakes_analyzer', AccumulatedMistakesAnalyzerWorker)
    logger.info(f"å·²æ³¨å†Œä»»åŠ¡ç±»å‹: {task_registry.list_task_types()}")


async def start_worker_pool():
    """å¯åŠ¨ worker æ± """
    global worker_tasks
    
    logger.info(f"å¯åŠ¨ {config.WORKER_CONCURRENCY} ä¸ªå¹¶å‘ worker...")
    
    for i in range(config.WORKER_CONCURRENCY):
        task = asyncio.create_task(worker_loop(worker_id=i))
        worker_tasks.append(task)
    
    logger.info("Worker æ± å·²å¯åŠ¨")


async def worker_loop(worker_id: int):
    """
    Worker å¾ªç¯ - æŒç»­ä»é˜Ÿåˆ—ä¸­å–ä»»åŠ¡å¹¶å¤„ç†
    
    Args:
        worker_id: Worker ID
    """
    worker_name = f"Worker-{worker_id}"
    logger.info(f"{worker_name} å¯åŠ¨")
    
    while True:
        try:
            # ä»é˜Ÿåˆ—å–ä»»åŠ¡ï¼ˆè¶…æ—¶ 1 ç§’ï¼‰
            task = await task_queue.dequeue(timeout=1.0)
            
            if not task:
                # æ²¡æœ‰ä»»åŠ¡ï¼Œç»§ç»­ç­‰å¾…
                await asyncio.sleep(0.1)
                continue
            
            task_id = task['task_id']
            task_type = task['task_type']
            task_data = task['task_data']
            
            logger.info(f"[{worker_name}] å¼€å§‹å¤„ç†: {task_id} (ç±»å‹: {task_type})")
            
            try:
                # è·å–å¯¹åº”çš„ worker ç±»
                worker_class = task_registry.get_worker_class(task_type)
                worker = worker_class()
                
                # æ‰§è¡Œä»»åŠ¡ï¼ˆå¸¦è¶…æ—¶ï¼‰
                result = await asyncio.wait_for(
                    worker.execute(task_id, task_data),
                    timeout=config.WORKER_TIMEOUT
                )
                
                # æ ‡è®°ä»»åŠ¡å®Œæˆæˆ–å¤±è´¥
                if result['success']:
                    await task_queue.mark_completed(task_id, result.get('result'))
                    logger.info(f"âœ… [{worker_name}] ä»»åŠ¡å®Œæˆ: {task_id}")
                else:
                    await task_queue.mark_failed(task_id, result.get('error', 'æœªçŸ¥é”™è¯¯'))
                    logger.error(f"âŒ [{worker_name}] ä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {result.get('error')}")
                
            except asyncio.TimeoutError:
                error_msg = f"ä»»åŠ¡è¶…æ—¶ï¼ˆ{config.WORKER_TIMEOUT}ç§’ï¼‰"
                await task_queue.mark_failed(task_id, error_msg)
                logger.error(f"â±ï¸ [{worker_name}] ä»»åŠ¡è¶…æ—¶: {task_id}")
                
            except KeyError as e:
                error_msg = f"æœªæ³¨å†Œçš„ä»»åŠ¡ç±»å‹: {task_type}"
                await task_queue.mark_failed(task_id, error_msg)
                logger.error(f"âŒ [{worker_name}] {error_msg}")
                
            except Exception as e:
                error_msg = f"Worker å¼‚å¸¸: {str(e)}"
                await task_queue.mark_failed(task_id, error_msg)
                logger.exception(f"ğŸ’¥ [{worker_name}] å‘ç”Ÿå¼‚å¸¸: {task_id}")
        
        except Exception as e:
            # Worker å¾ªç¯æœ¬èº«çš„å¼‚å¸¸ï¼Œè®°å½•ä½†ä¸é€€å‡º
            logger.exception(f"ğŸ’¥ [{worker_name}] å¾ªç¯å¼‚å¸¸: {str(e)}")
            await asyncio.sleep(1.0)


async def stop_worker_pool():
    """åœæ­¢ worker æ± """
    global worker_tasks
    
    logger.info("åœæ­¢ worker æ± ...")
    
    for task in worker_tasks:
        task.cancel()
    
    await asyncio.gather(*worker_tasks, return_exceptions=True)
    worker_tasks.clear()
    
    logger.info("Worker æ± å·²åœæ­¢")


@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    logger.info("åˆå§‹åŒ– Worker ç³»ç»Ÿ...")
    
    await init_queue()
    register_workers()
    await start_worker_pool()
    
    logger.info("Worker ç³»ç»Ÿå·²å¯åŠ¨")
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    logger.info("å…³é—­ Worker ç³»ç»Ÿ...")
    await stop_worker_pool()
    logger.info("Worker ç³»ç»Ÿå·²å…³é—­")


# ========== FastAPI åº”ç”¨ ==========

app = FastAPI(
    title="SureUp Worker API",
    description="å¼‚æ­¥ä»»åŠ¡å¤„ç†ç³»ç»Ÿ - æ”¯æŒé«˜å¹¶å‘é•¿æ—¶é—´ä»»åŠ¡",
    version="1.0.0",
    lifespan=lifespan
)


# ========== API è·¯ç”± ==========

@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "running",
        "message": "SureUp Worker API",
        "version": "1.0.0"
    }


@app.post("/tasks/enqueue", response_model=TaskResponse)
async def enqueue_task(task: TaskBase):
    """
    å°†ä»»åŠ¡åŠ å…¥é˜Ÿåˆ—
    
    Args:
        task: ä»»åŠ¡æ•°æ®
        
    Returns:
        ä»»åŠ¡IDå’ŒçŠ¶æ€
    """
    try:
        task_id = await task_queue.enqueue(
            task_type=task.task_type,
            task_data=task.task_data,
            priority=task.priority
        )
        
        logger.info(f"ä»»åŠ¡å·²å…¥é˜Ÿ: {task_id} (ç±»å‹: {task.task_type})")
        
        return TaskResponse(
            task_id=task_id,
            status="pending",
            message="ä»»åŠ¡å·²å…¥é˜Ÿ"
        )
    except Exception as e:
        logger.error(f"å…¥é˜Ÿå¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/tasks/{task_id}", response_model=TaskStatus)
async def get_task_status(task_id: str):
    """
    è·å–ä»»åŠ¡çŠ¶æ€
    
    Args:
        task_id: ä»»åŠ¡ID
        
    Returns:
        ä»»åŠ¡çŠ¶æ€ä¿¡æ¯
    """
    try:
        status = await task_queue.get_task_status(task_id)
        
        if not status:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
        
        return TaskStatus(**status)
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/queue/stats", response_model=QueueStats)
async def get_queue_stats():
    """
    è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯
    
    Returns:
        é˜Ÿåˆ—ç»Ÿè®¡æ•°æ®
    """
    try:
        stats = await task_queue.get_queue_stats()
        return QueueStats(**stats)
    except Exception as e:
        logger.error(f"è·å–é˜Ÿåˆ—ç»Ÿè®¡å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/workers/types")
async def list_worker_types():
    """
    åˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„ worker ç±»å‹
    
    Returns:
        Worker ç±»å‹åˆ—è¡¨
    """
    return {
        "worker_types": task_registry.list_task_types(),
        "concurrency": config.WORKER_CONCURRENCY
    }


# ========== é”™è¯¯å¤„ç† ==========

@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """å…¨å±€å¼‚å¸¸å¤„ç†"""
    logger.exception(f"æœªå¤„ç†çš„å¼‚å¸¸: {str(exc)}")
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "message": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯",
            "detail": str(exc)
        }
    )


# ========== ä¸»å…¥å£ ==========

if __name__ == "__main__":
    import uvicorn
    
    # é…ç½®æ—¥å¿—
    logger.add(
        "logs/worker_{time}.log",
        rotation="100 MB",
        retention="30 days",
        level=config.LOG_LEVEL
    )
    
    logger.info("å¯åŠ¨ Worker API æœåŠ¡å™¨...")
    logger.info(f"ç›‘å¬åœ°å€: {config.API_HOST}:{config.API_PORT}")
    logger.info(f"å¹¶å‘æ•°: {config.WORKER_CONCURRENCY}")
    logger.info(f"é˜Ÿåˆ—ç±»å‹: {config.QUEUE_TYPE}")
    
    uvicorn.run(
        "app:app",
        host=config.API_HOST,
        port=config.API_PORT,
        workers=config.API_WORKERS,
        log_level=config.LOG_LEVEL.lower()
    )

